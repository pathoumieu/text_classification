{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import standard packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:47:35.311983Z",
     "start_time": "2019-02-26T21:47:34.070267Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import custom packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:47:35.355703Z",
     "start_time": "2019-02-26T21:47:35.314182Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from text_classification import load_data, preprocess_sequences, extract_features\n",
    "    from text_classification.model import Hybrid_RNN, max_f1\n",
    "except ImportError as e:\n",
    "    print('Please install \"text_classification\" package (`pip install text_classification` in root directory)')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:13:04.089311Z",
     "start_time": "2019-02-26T21:12:56.063485Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_sequences.main(data_dir='Data', max_len=133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "* with raw sequences\n",
    "* without features, since they are not created yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T19:17:15.823494Z",
     "start_time": "2019-02-12T19:17:15.663907Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data.load_train(data_dir='Data', features=False, processed_sequences=False)\n",
    "test = load_data.load_test(data_dir='Data', features=False, processed_sequences=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T19:18:33.547941Z",
     "start_time": "2019-02-12T19:17:17.875185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathoumieu/Documents/Deep_Learning_tuto/text_analysis/arturin-deeplearning-test-all/venvv/lib/python3.5/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/pathoumieu/Documents/Deep_Learning_tuto/text_analysis/arturin-deeplearning-test-all/text_classification/extract_features.py:164: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  train_features = pd.DataFrame(scaler.transform(train_features), columns=train_features.columns)\n",
      "/home/pathoumieu/Documents/Deep_Learning_tuto/text_analysis/arturin-deeplearning-test-all/text_classification/extract_features.py:165: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  test_features = pd.DataFrame(scaler.transform(test_features), columns=test_features.columns)\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'Data'\n",
    "extract_features.main(train, test, output_dir, max_features=20000, n_components=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:47:43.668099Z",
     "start_time": "2019-02-26T21:47:39.056860Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, feature_cols = load_data.load_train(data_dir='Data', features=True, processed_sequences=True)\n",
    "test, feature_cols = load_data.load_test(data_dir='Data', features=True, processed_sequences=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variable and functions definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define class weights for binary cross entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:47:43.673911Z",
     "start_time": "2019-02-26T21:47:43.670152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class1_weight = np.bincount(train.labels.values)[0] * 1.0 / np.bincount(train.labels.values)[1]\n",
    "class_weight = {0: 1, 1: class1_weight}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define max_len and max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:47:43.678486Z",
     "start_time": "2019-02-26T21:47:43.675763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 133       # Maximum length of sequences in Train and Test\n",
    "max_words = 30432   # Total number of tokens in Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dummy test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take an artificial test set in Train data (10%) in order to assess the performance of the models on a dataset that is not used for either training of early stopping validation.\n",
    "\n",
    "Stratified Shuffle Split allows to keep the labels distribution in Train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:47:43.769468Z",
     "start_time": "2019-02-26T21:47:43.680882Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "sss.get_n_splits(train, train.labels)\n",
    "\n",
    "for train_index, test_index in sss.split(train, train.labels):\n",
    "    df_train, df_test = train.iloc[train_index], train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameter search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Hyperparameter `search_space` is a list of dictionnaries of all possibilities for hyperparameters, defined in `hyperparams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:47:43.778411Z",
     "start_time": "2019-02-26T21:47:43.771482Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparams = {'learning_rate':            [1e-3, 1e-4],\n",
    "               'embedding_size':           [64, 128, 256],\n",
    "               'dense_size_features':      [128, 256, 512],\n",
    "               'dense_size_concat':        [64, 128, 256],\n",
    "               'add_dense':                [None, 16, 32, 64],\n",
    "               'dropout_rate':             [0.3, 0.4, 0.5],\n",
    "               'lstm_size':                [32, 64]}\n",
    "\n",
    "keys, values = zip(*hyperparams.items())\n",
    "\n",
    "search_space = []\n",
    "for state in itertools.product(*values):\n",
    "    search_space.append(dict(zip(keys, state)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cross validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:47:43.791333Z",
     "start_time": "2019-02-26T21:47:43.780228Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(df_train, df_train.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given sample of `search_space`, 5 fold Stratified Cross Validation is performed. Early Stopping on valid maximum F1-score is performed.\n",
    "\n",
    "The five trained models are then stacked taking the average scores, and the performance is assessed on the artificial test by looking at the accuracy. The threshold for test accuracy computation is chosen by taking the average of thresholds that maximize accuracy on the 5 validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:49:01.120899Z",
     "start_time": "2019-02-26T21:47:43.793091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "=====\n",
      "Training on hyper dict no 1\n",
      "=====\n",
      "{'dense_size_features': 256, 'lstm_size': 32, 'add_dense': None, 'embedding_size': 256, 'dense_size_concat': 64, 'learning_rate': 0.0001, 'dropout_rate': 0.5}\n",
      "=====\n",
      "========\n",
      "Fold 1\n",
      "========\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5574 - f1_score_K: 0.1804 - val_loss: 0.7389 - val_f1_score_K: 0.2339\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3279 - f1_score_K: 0.2688 - val_loss: 0.6366 - val_f1_score_K: 0.2909\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1185 - f1_score_K: 0.3758 - val_loss: 0.5307 - val_f1_score_K: 0.3786\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8655 - f1_score_K: 0.4711 - val_loss: 0.5875 - val_f1_score_K: 0.3353\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4806 - f1_score_K: 0.7189 - val_loss: 0.4546 - val_f1_score_K: 0.3548\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "========\n",
      "Fold 2\n",
      "========\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.5788 - f1_score_K: 0.1743 - val_loss: 0.5946 - val_f1_score_K: 0.2734\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0461 - f1_score_K: 0.3073 - val_loss: 0.5073 - val_f1_score_K: 0.2459\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9856 - f1_score_K: 0.3784 - val_loss: 0.4560 - val_f1_score_K: 0.3087\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8207 - f1_score_K: 0.4233 - val_loss: 0.4438 - val_f1_score_K: 0.4015\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6868 - f1_score_K: 0.4074 - val_loss: 0.3930 - val_f1_score_K: 0.0514\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9167 - f1_score_K: 0.4560 - val_loss: 0.5107 - val_f1_score_K: 0.3617\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00006: early stopping\n",
      "========\n",
      "Fold 3\n",
      "========\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.4125 - f1_score_K: 0.1854 - val_loss: 0.7063 - val_f1_score_K: 0.2797\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.1657 - f1_score_K: 0.2550 - val_loss: 0.5905 - val_f1_score_K: 0.3405\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9674 - f1_score_K: 0.3403 - val_loss: 0.4968 - val_f1_score_K: 0.3108\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8171 - f1_score_K: 0.4453 - val_loss: 0.5877 - val_f1_score_K: 0.3720\n",
      "Epoch 5/20\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.5371 - f1_score_K: 0.5973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f44ff1ba3ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m                    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                    patience=2)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Score model on small_valid and df_test, select best threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Deep_Learning_tuto/text_analysis/text_classification/text_classification/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_matrix, train_features, train_labels, valid_matrix, valid_features, valid_labels, class_weight, epochs, patience)\u001b[0m\n\u001b[1;32m    215\u001b[0m                                                 \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                                 restore_best_weights=True)])\n\u001b[0m",
      "\u001b[0;32m~/Documents/Deep_Learning_tuto/venv_p3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Documents/Deep_Learning_tuto/venv_p3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Deep_Learning_tuto/venv_p3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Deep_Learning_tuto/venv_p3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Deep_Learning_tuto/venv_p3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Deep_Learning_tuto/venv_p3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Define output_dir\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "output_dir = 'results/' + st\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "# Number of random samples taken in `search_space`\n",
    "no_it = 1\n",
    "\n",
    "for hyperparameters_dict, it in zip(np.random.permutation(search_space), range(no_it)):\n",
    "    \n",
    "    print('=====')\n",
    "    print('=====')\n",
    "    print('Training on hyper dict no ' + str(it + 1))\n",
    "    print('=====')\n",
    "    print(str(hyperparameters_dict))\n",
    "    print('=====')\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['hyperparameters'] = hyperparameters_dict\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    # Iterate on folds for cross validation\n",
    "    for train_index, test_index in skf.split(df_train, df_train.labels):\n",
    "                \n",
    "        fold = 'Fold ' + str(i + 1)\n",
    "        print('========')\n",
    "        print(fold)\n",
    "        print('========')\n",
    "        \n",
    "        cross_val_dict = {}\n",
    "        \n",
    "        # Define model\n",
    "        hrnn = Hybrid_RNN(max_words=max_words, max_len=max_len)\n",
    "        hrnn.init_hyperparams(hyperparameters_dict)\n",
    "        hrnn.init_network(feature_cols)\n",
    "        \n",
    "        # Split\n",
    "        small_train, small_valid = df_train.iloc[train_index].iloc[:1000], df_train.iloc[test_index].iloc[:1000]\n",
    "        \n",
    "        # Pad sequences\n",
    "        sequences_train_matrix = sequence.pad_sequences(small_train['sequence'], maxlen=max_len, value=2)\n",
    "        sequences_valid_matrix = sequence.pad_sequences(small_valid['sequence'], maxlen=max_len, value=2)\n",
    "        sequences_test_matrix = sequence.pad_sequences(df_test['sequence'], maxlen=max_len, value=2)\n",
    "\n",
    "        # Train model on small_train, small_valid\n",
    "        hrnn.train(sequences_train_matrix, small_train[feature_cols], small_train.labels,\n",
    "                   sequences_valid_matrix, small_valid[feature_cols], small_valid.labels,\n",
    "                   class_weight=class_weight,\n",
    "                   epochs=10,\n",
    "                   patience=2)\n",
    "        \n",
    "        # Score model on small_valid and df_test, select best threshold\n",
    "        ## Predict\n",
    "        y_pred_valid = hrnn.model.predict([sequences_valid_matrix, small_valid[feature_cols]]).flatten()\n",
    "        y_pred_test = hrnn.model.predict([sequences_test_matrix, df_test[feature_cols]]).flatten()\n",
    "        \n",
    "        cross_val_dict['y_pred_test'] = y_pred_test\n",
    "                \n",
    "        y_true_valid = small_valid.labels\n",
    "        y_true_test = df_test.labels\n",
    "                \n",
    "        ## Compute accuracy at threshold 0.5 for valid, test\n",
    "        cross_val_dict['f1_05_valid'] = f1_score(y_true_valid, (y_pred_valid >= 0.5))\n",
    "        cross_val_dict['f1_05_test'] = f1_score(y_true_test, (y_pred_test >= 0.5))\n",
    "                \n",
    "        ## Compute max accuracy on valid, and corresponding threshold\n",
    "        cross_val_dict['best_f1_valid'], cross_val_dict['best_thresh_valid'] = max_f1(y_true_valid, y_pred_valid)\n",
    "        \n",
    "        ## Compute accuracy on test for threshold that maximizes accuracy on valid\n",
    "        cross_val_dict['f1_thresh_test'] = f1_score(y_true_test, (y_pred_test >= cross_val_dict['best_thresh_valid']))\n",
    "    \n",
    "        result_dict[fold] = cross_val_dict\n",
    "        \n",
    "        # Save result_dict\n",
    "        ts = time.time()\n",
    "        st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open(output_dir + '/result_dict_it_' + str(it) + '_Fold_' + str(i) + '_' + st + '.pkl', 'wb') as f:\n",
    "            pkl.dump(result_dict, f)\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "    results.append(result_dict)\n",
    "    \n",
    "for result_dict in results:\n",
    "    # Stack models\n",
    "    ## Compute average predictions on test over folds\n",
    "    result_dict['stacked_y_pred'] = np.mean(np.array([result_dict[fold]['y_pred_test'] for fold in ['Fold ' + str(i + 1) for i in range(5)]]), axis=0)\n",
    "    \n",
    "    ## Compute average threshold over folds for valid\n",
    "    result_dict['stacked_thresh_valid'] = np.mean([result_dict[fold]['best_thresh_valid'] for fold in ['Fold ' + str(i + 1) for i in range(5)]])\n",
    "    \n",
    "    ## Compute accuracy at threshold 0.5 on stacked predictions on test\n",
    "    result_dict['f1_05_test_stacking'] = f1_score(y_true_test, (result_dict['stacked_y_pred'] >= 0.5))\n",
    "    \n",
    "    ## Compute accuracy at average best threshold on stacked predictions on test \n",
    "    result_dict['f1_thresh_test_stacking'] = f1_score(y_true_test, (result_dict['stacked_y_pred'] >= result_dict['stacked_thresh_valid']))\n",
    "\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')            \n",
    "with open(output_dir + '/all_result_list_' + st + '.pkl', 'wb') as f:\n",
    "    pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train final models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:49:01.122969Z",
     "start_time": "2019-02-26T21:47:43.574Z"
    }
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(train, train.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T19:36:40.916243Z",
     "start_time": "2019-02-12T19:36:40.906332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_hyperparameters = {'add_dense': 32, \n",
    "                        'dense_size_features': 128, \n",
    "                        'dense_size_concat': 256, \n",
    "                        'lstm_size': 64, \n",
    "                        'learning_rate': 0.0001, \n",
    "                        'val_metric': 'val_acc', \n",
    "                        'embedding_size': 256, \n",
    "                        'dropout_rate': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:45:35.538800Z",
     "start_time": "2019-02-12T19:37:33.186616Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "Fold 1\n",
      "========\n",
      "Train on 36743 samples, validate on 9187 samples\n",
      "Epoch 1/20\n",
      "36743/36743 [==============================] - 113s 3ms/step - loss: 1.0438 - acc: 0.6806 - auc: 0.6736 - val_loss: 0.5135 - val_acc: 0.7554 - val_auc: 0.7548\n",
      "Epoch 2/20\n",
      "36743/36743 [==============================] - 113s 3ms/step - loss: 0.6922 - acc: 0.8194 - auc: 0.8096 - val_loss: 0.4063 - val_acc: 0.8102 - val_auc: 0.8406\n",
      "Epoch 3/20\n",
      "36743/36743 [==============================] - 113s 3ms/step - loss: 0.4783 - acc: 0.8774 - auc: 0.8651 - val_loss: 0.3941 - val_acc: 0.8097 - val_auc: 0.8824\n",
      "Epoch 4/20\n",
      "36743/36743 [==============================] - 113s 3ms/step - loss: 0.3263 - acc: 0.9175 - auc: 0.8960 - val_loss: 0.5205 - val_acc: 0.7971 - val_auc: 0.9075\n",
      "Epoch 5/20\n",
      "36743/36743 [==============================] - 113s 3ms/step - loss: 0.2361 - acc: 0.9394 - auc: 0.9150 - val_loss: 0.5051 - val_acc: 0.8394 - val_auc: 0.9238\n",
      "Epoch 6/20\n",
      "36743/36743 [==============================] - 112s 3ms/step - loss: 0.1773 - acc: 0.9560 - auc: 0.9269 - val_loss: 0.4831 - val_acc: 0.8556 - val_auc: 0.9336\n",
      "Epoch 7/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.1324 - acc: 0.9665 - auc: 0.9351 - val_loss: 0.6466 - val_acc: 0.8485 - val_auc: 0.9402\n",
      "Epoch 8/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.1018 - acc: 0.9746 - auc: 0.9407 - val_loss: 0.6143 - val_acc: 0.8564 - val_auc: 0.9448\n",
      "Epoch 9/20\n",
      "36743/36743 [==============================] - 111s 3ms/step - loss: 0.0779 - acc: 0.9812 - auc: 0.9453 - val_loss: 0.7986 - val_acc: 0.8307 - val_auc: 0.9485\n",
      "Epoch 10/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.0795 - acc: 0.9816 - auc: 0.9487 - val_loss: 0.7886 - val_acc: 0.8465 - val_auc: 0.9514\n",
      "Epoch 11/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.0618 - acc: 0.9856 - auc: 0.9511 - val_loss: 0.8894 - val_acc: 0.8353 - val_auc: 0.9532\n",
      "Epoch 12/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.0746 - acc: 0.9832 - auc: 0.9531 - val_loss: 0.8094 - val_acc: 0.8710 - val_auc: 0.9550\n",
      "Epoch 13/20\n",
      "36743/36743 [==============================] - 111s 3ms/step - loss: 0.0539 - acc: 0.9881 - auc: 0.9534 - val_loss: 0.8120 - val_acc: 0.8584 - val_auc: 0.9552\n",
      "Epoch 14/20\n",
      "36743/36743 [==============================] - 111s 3ms/step - loss: 0.0365 - acc: 0.9914 - auc: 0.9546 - val_loss: 0.8638 - val_acc: 0.8540 - val_auc: 0.9562\n",
      "Epoch 15/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.0594 - acc: 0.9872 - auc: 0.9555 - val_loss: 0.9781 - val_acc: 0.8437 - val_auc: 0.9567\n",
      "Epoch 16/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.0370 - acc: 0.9914 - auc: 0.9563 - val_loss: 0.9709 - val_acc: 0.8487 - val_auc: 0.9575\n",
      "Epoch 17/20\n",
      "36743/36743 [==============================] - 115s 3ms/step - loss: 0.0315 - acc: 0.9934 - auc: 0.9569 - val_loss: 0.9659 - val_acc: 0.8671 - val_auc: 0.9581\n",
      "Epoch 18/20\n",
      "36743/36743 [==============================] - 119s 3ms/step - loss: 0.0227 - acc: 0.9952 - auc: 0.9572 - val_loss: 1.0369 - val_acc: 0.8721 - val_auc: 0.9583\n",
      "Epoch 19/20\n",
      "36743/36743 [==============================] - 112s 3ms/step - loss: 0.0480 - acc: 0.9908 - auc: 0.9573 - val_loss: 0.9160 - val_acc: 0.8614 - val_auc: 0.9582\n",
      "Epoch 20/20\n",
      "36743/36743 [==============================] - 115s 3ms/step - loss: 0.0410 - acc: 0.9921 - auc: 0.9576 - val_loss: 0.8868 - val_acc: 0.8622 - val_auc: 0.9585\n",
      "========\n",
      "Fold 2\n",
      "========\n",
      "Train on 36743 samples, validate on 9187 samples\n",
      "Epoch 1/20\n",
      "36743/36743 [==============================] - 114s 3ms/step - loss: 1.0373 - acc: 0.6912 - auc: 0.6830 - val_loss: 0.6394 - val_acc: 0.6780 - val_auc: 0.7565\n",
      "Epoch 2/20\n",
      "36743/36743 [==============================] - 115s 3ms/step - loss: 0.6562 - acc: 0.8306 - auc: 0.8196 - val_loss: 0.4648 - val_acc: 0.7716 - val_auc: 0.8477\n",
      "Epoch 3/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.4417 - acc: 0.8867 - auc: 0.8732 - val_loss: 0.3623 - val_acc: 0.8549 - val_auc: 0.8912\n",
      "Epoch 4/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.3012 - acc: 0.9226 - auc: 0.9008 - val_loss: 0.4286 - val_acc: 0.8431 - val_auc: 0.9130\n",
      "Epoch 5/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.2096 - acc: 0.9471 - auc: 0.9194 - val_loss: 0.4699 - val_acc: 0.8452 - val_auc: 0.9281\n",
      "Epoch 6/20\n",
      "36743/36743 [==============================] - 116s 3ms/step - loss: 0.1538 - acc: 0.9609 - auc: 0.9314 - val_loss: 0.6096 - val_acc: 0.8544 - val_auc: 0.9378\n",
      "Epoch 7/20\n",
      "36743/36743 [==============================] - 123s 3ms/step - loss: 0.1371 - acc: 0.9661 - auc: 0.9383 - val_loss: 0.5078 - val_acc: 0.8597 - val_auc: 0.9432\n",
      "Epoch 8/20\n",
      "36743/36743 [==============================] - 111s 3ms/step - loss: 0.0945 - acc: 0.9776 - auc: 0.9438 - val_loss: 0.7407 - val_acc: 0.8630 - val_auc: 0.9477\n",
      "Epoch 9/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.0896 - acc: 0.9786 - auc: 0.9473 - val_loss: 0.7154 - val_acc: 0.8642 - val_auc: 0.9504\n",
      "Epoch 10/20\n",
      "36743/36743 [==============================] - 113s 3ms/step - loss: 0.0579 - acc: 0.9858 - auc: 0.9497 - val_loss: 0.8057 - val_acc: 0.8621 - val_auc: 0.9525\n",
      "Epoch 11/20\n",
      "36743/36743 [==============================] - 109s 3ms/step - loss: 0.0640 - acc: 0.9842 - auc: 0.9515 - val_loss: 0.8526 - val_acc: 0.8745 - val_auc: 0.9539\n",
      "Epoch 12/20\n",
      "36743/36743 [==============================] - 109s 3ms/step - loss: 0.0706 - acc: 0.9845 - auc: 0.9525 - val_loss: 0.9785 - val_acc: 0.8344 - val_auc: 0.9543\n",
      "Epoch 13/20\n",
      "36743/36743 [==============================] - 111s 3ms/step - loss: 0.0641 - acc: 0.9849 - auc: 0.9541 - val_loss: 0.7650 - val_acc: 0.8669 - val_auc: 0.9558\n",
      "Epoch 14/20\n",
      "36743/36743 [==============================] - 112s 3ms/step - loss: 0.0500 - acc: 0.9895 - auc: 0.9551 - val_loss: 0.8094 - val_acc: 0.8463 - val_auc: 0.9565\n",
      "Epoch 15/20\n",
      "36743/36743 [==============================] - 110s 3ms/step - loss: 0.0257 - acc: 0.9944 - auc: 0.9563 - val_loss: 1.0019 - val_acc: 0.8568 - val_auc: 0.9577\n",
      "Epoch 16/20\n",
      "36743/36743 [==============================] - 111s 3ms/step - loss: 0.0237 - acc: 0.9953 - auc: 0.9569 - val_loss: 1.1102 - val_acc: 0.8618 - val_auc: 0.9581\n",
      "Epoch 17/20\n",
      "36743/36743 [==============================] - 112s 3ms/step - loss: 0.0467 - acc: 0.9904 - auc: 0.9572 - val_loss: 0.8982 - val_acc: 0.8553 - val_auc: 0.9582\n",
      "Epoch 18/20\n",
      "36743/36743 [==============================] - 111s 3ms/step - loss: 0.0298 - acc: 0.9943 - auc: 0.9578 - val_loss: 0.9416 - val_acc: 0.8649 - val_auc: 0.9588\n",
      "Epoch 19/20\n",
      "36743/36743 [==============================] - 117s 3ms/step - loss: 0.0152 - acc: 0.9967 - auc: 0.9580 - val_loss: 1.1649 - val_acc: 0.8602 - val_auc: 0.9590\n",
      "Epoch 20/20\n",
      "36743/36743 [==============================] - 115s 3ms/step - loss: 0.0226 - acc: 0.9956 - auc: 0.9581 - val_loss: 1.1204 - val_acc: 0.8590 - val_auc: 0.9590\n",
      "========\n",
      "Fold 3\n",
      "========\n",
      "Train on 36744 samples, validate on 9186 samples\n",
      "Epoch 1/20\n",
      "36744/36744 [==============================] - 117s 3ms/step - loss: 1.0670 - acc: 0.6801 - auc: 0.6650 - val_loss: 0.4761 - val_acc: 0.7778 - val_auc: 0.7456\n",
      "Epoch 2/20\n",
      "36744/36744 [==============================] - 114s 3ms/step - loss: 0.7581 - acc: 0.7971 - auc: 0.7948 - val_loss: 0.5473 - val_acc: 0.7432 - val_auc: 0.8189\n",
      "Epoch 3/20\n",
      "36744/36744 [==============================] - 114s 3ms/step - loss: 0.5117 - acc: 0.8680 - auc: 0.8487 - val_loss: 0.4062 - val_acc: 0.8096 - val_auc: 0.8681\n",
      "Epoch 4/20\n",
      "36744/36744 [==============================] - 113s 3ms/step - loss: 0.3730 - acc: 0.9048 - auc: 0.8836 - val_loss: 0.4377 - val_acc: 0.8107 - val_auc: 0.8962\n",
      "Epoch 5/20\n",
      "36744/36744 [==============================] - 112s 3ms/step - loss: 0.2593 - acc: 0.9342 - auc: 0.9053 - val_loss: 0.4757 - val_acc: 0.8487 - val_auc: 0.9153\n",
      "Epoch 6/20\n",
      "36744/36744 [==============================] - 110s 3ms/step - loss: 0.1812 - acc: 0.9538 - auc: 0.9192 - val_loss: 0.5184 - val_acc: 0.8550 - val_auc: 0.9268\n",
      "Epoch 7/20\n",
      "36744/36744 [==============================] - 107s 3ms/step - loss: 0.1337 - acc: 0.9672 - auc: 0.9292 - val_loss: 0.6859 - val_acc: 0.8283 - val_auc: 0.9349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "36744/36744 [==============================] - 106s 3ms/step - loss: 0.0977 - acc: 0.9764 - auc: 0.9366 - val_loss: 0.8245 - val_acc: 0.8055 - val_auc: 0.9408\n",
      "Epoch 9/20\n",
      "36744/36744 [==============================] - 106s 3ms/step - loss: 0.0938 - acc: 0.9764 - auc: 0.9418 - val_loss: 0.7851 - val_acc: 0.8424 - val_auc: 0.9454\n",
      "Epoch 10/20\n",
      "36744/36744 [==============================] - 106s 3ms/step - loss: 0.0790 - acc: 0.9810 - auc: 0.9452 - val_loss: 0.8276 - val_acc: 0.8541 - val_auc: 0.9482\n",
      "Epoch 11/20\n",
      "36744/36744 [==============================] - 113s 3ms/step - loss: 0.0663 - acc: 0.9842 - auc: 0.9475 - val_loss: 0.8497 - val_acc: 0.8245 - val_auc: 0.9499\n",
      "Epoch 12/20\n",
      "36744/36744 [==============================] - 112s 3ms/step - loss: 0.0510 - acc: 0.9876 - auc: 0.9500 - val_loss: 0.9180 - val_acc: 0.8490 - val_auc: 0.9522\n",
      "Epoch 13/20\n",
      "36744/36744 [==============================] - 111s 3ms/step - loss: 0.0500 - acc: 0.9893 - auc: 0.9514 - val_loss: 0.9845 - val_acc: 0.8586 - val_auc: 0.9533\n",
      "Epoch 14/20\n",
      "36744/36744 [==============================] - 113s 3ms/step - loss: 0.0410 - acc: 0.9906 - auc: 0.9524 - val_loss: 0.9145 - val_acc: 0.8570 - val_auc: 0.9541\n",
      "Epoch 15/20\n",
      "36744/36744 [==============================] - 109s 3ms/step - loss: 0.0501 - acc: 0.9894 - auc: 0.9533 - val_loss: 0.9474 - val_acc: 0.8488 - val_auc: 0.9548\n",
      "Epoch 16/20\n",
      "36744/36744 [==============================] - 107s 3ms/step - loss: 0.0350 - acc: 0.9917 - auc: 0.9543 - val_loss: 1.0313 - val_acc: 0.8462 - val_auc: 0.9556\n",
      "Epoch 17/20\n",
      "36744/36744 [==============================] - 109s 3ms/step - loss: 0.0313 - acc: 0.9933 - auc: 0.9549 - val_loss: 1.1837 - val_acc: 0.8457 - val_auc: 0.9561\n",
      "Epoch 18/20\n",
      "36744/36744 [==============================] - 110s 3ms/step - loss: 0.0317 - acc: 0.9931 - auc: 0.9554 - val_loss: 1.0783 - val_acc: 0.8586 - val_auc: 0.9566\n",
      "Epoch 19/20\n",
      "36744/36744 [==============================] - 107s 3ms/step - loss: 0.0230 - acc: 0.9950 - auc: 0.9558 - val_loss: 1.2961 - val_acc: 0.8575 - val_auc: 0.9568\n",
      "Epoch 20/20\n",
      "36744/36744 [==============================] - 107s 3ms/step - loss: 0.0258 - acc: 0.9949 - auc: 0.9560 - val_loss: 1.1651 - val_acc: 0.8502 - val_auc: 0.9569\n",
      "========\n",
      "Fold 4\n",
      "========\n",
      "Train on 36745 samples, validate on 9185 samples\n",
      "Epoch 1/20\n",
      "36745/36745 [==============================] - 115s 3ms/step - loss: 1.0272 - acc: 0.6979 - auc: 0.6709 - val_loss: 0.4504 - val_acc: 0.8165 - val_auc: 0.7684\n",
      "Epoch 2/20\n",
      "36745/36745 [==============================] - 126s 3ms/step - loss: 0.6497 - acc: 0.8364 - auc: 0.8253 - val_loss: 0.3810 - val_acc: 0.8294 - val_auc: 0.8537\n",
      "Epoch 3/20\n",
      "36745/36745 [==============================] - 114s 3ms/step - loss: 0.4274 - acc: 0.8974 - auc: 0.8771 - val_loss: 0.3258 - val_acc: 0.8594 - val_auc: 0.8953\n",
      "Epoch 4/20\n",
      "36745/36745 [==============================] - 114s 3ms/step - loss: 0.2953 - acc: 0.9248 - auc: 0.9048 - val_loss: 0.5103 - val_acc: 0.8030 - val_auc: 0.9157\n",
      "Epoch 5/20\n",
      "36745/36745 [==============================] - 114s 3ms/step - loss: 0.2064 - acc: 0.9498 - auc: 0.9233 - val_loss: 0.4935 - val_acc: 0.8217 - val_auc: 0.9313\n",
      "Epoch 6/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.1529 - acc: 0.9617 - auc: 0.9352 - val_loss: 0.5388 - val_acc: 0.8550 - val_auc: 0.9412\n",
      "Epoch 7/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.1125 - acc: 0.9716 - auc: 0.9422 - val_loss: 0.6694 - val_acc: 0.8655 - val_auc: 0.9469\n",
      "Epoch 8/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.0909 - acc: 0.9777 - auc: 0.9466 - val_loss: 0.6595 - val_acc: 0.8631 - val_auc: 0.9504\n",
      "Epoch 9/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.1095 - acc: 0.9754 - auc: 0.9501 - val_loss: 0.5779 - val_acc: 0.8658 - val_auc: 0.9528\n",
      "Epoch 10/20\n",
      "36745/36745 [==============================] - 111s 3ms/step - loss: 0.0747 - acc: 0.9830 - auc: 0.9523 - val_loss: 0.8200 - val_acc: 0.8447 - val_auc: 0.9547\n",
      "Epoch 11/20\n",
      "36745/36745 [==============================] - 113s 3ms/step - loss: 0.0531 - acc: 0.9888 - auc: 0.9546 - val_loss: 0.8384 - val_acc: 0.8627 - val_auc: 0.9568\n",
      "Epoch 12/20\n",
      "36745/36745 [==============================] - 115s 3ms/step - loss: 0.0456 - acc: 0.9907 - auc: 0.9561 - val_loss: 0.8338 - val_acc: 0.8410 - val_auc: 0.9579\n",
      "Epoch 13/20\n",
      "36745/36745 [==============================] - 114s 3ms/step - loss: 0.0419 - acc: 0.9908 - auc: 0.9578 - val_loss: 0.8446 - val_acc: 0.8514 - val_auc: 0.9593\n",
      "Epoch 14/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.0316 - acc: 0.9935 - auc: 0.9588 - val_loss: 0.8386 - val_acc: 0.8754 - val_auc: 0.9603\n",
      "Epoch 15/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.0518 - acc: 0.9909 - auc: 0.9592 - val_loss: 0.8421 - val_acc: 0.8511 - val_auc: 0.9604\n",
      "Epoch 16/20\n",
      "36745/36745 [==============================] - 111s 3ms/step - loss: 0.0312 - acc: 0.9933 - auc: 0.9600 - val_loss: 0.8934 - val_acc: 0.8697 - val_auc: 0.9612\n",
      "Epoch 17/20\n",
      "36745/36745 [==============================] - 114s 3ms/step - loss: 0.0170 - acc: 0.9965 - auc: 0.9602 - val_loss: 1.1346 - val_acc: 0.8615 - val_auc: 0.9613\n",
      "Epoch 18/20\n",
      "36745/36745 [==============================] - 116s 3ms/step - loss: 0.0149 - acc: 0.9966 - auc: 0.9605 - val_loss: 1.1527 - val_acc: 0.8643 - val_auc: 0.9614\n",
      "Epoch 19/20\n",
      "36745/36745 [==============================] - 113s 3ms/step - loss: 0.0263 - acc: 0.9953 - auc: 0.9607 - val_loss: 1.0430 - val_acc: 0.8660 - val_auc: 0.9616\n",
      "Epoch 20/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.0351 - acc: 0.9934 - auc: 0.9608 - val_loss: 0.9317 - val_acc: 0.8653 - val_auc: 0.9616\n",
      "========\n",
      "Fold 5\n",
      "========\n",
      "Train on 36745 samples, validate on 9185 samples\n",
      "Epoch 1/20\n",
      "36745/36745 [==============================] - 111s 3ms/step - loss: 1.0477 - acc: 0.6803 - auc: 0.6637 - val_loss: 0.5506 - val_acc: 0.7087 - val_auc: 0.7490\n",
      "Epoch 2/20\n",
      "36745/36745 [==============================] - 110s 3ms/step - loss: 0.7142 - acc: 0.8082 - auc: 0.8055 - val_loss: 0.5037 - val_acc: 0.7616 - val_auc: 0.8317\n",
      "Epoch 3/20\n",
      "36745/36745 [==============================] - 110s 3ms/step - loss: 0.4925 - acc: 0.8745 - auc: 0.8580 - val_loss: 0.5539 - val_acc: 0.7559 - val_auc: 0.8749\n",
      "Epoch 4/20\n",
      "36745/36745 [==============================] - 110s 3ms/step - loss: 0.3624 - acc: 0.9076 - auc: 0.8891 - val_loss: 0.4660 - val_acc: 0.8199 - val_auc: 0.9017\n",
      "Epoch 5/20\n",
      "36745/36745 [==============================] - 110s 3ms/step - loss: 0.2484 - acc: 0.9362 - auc: 0.9085 - val_loss: 0.4708 - val_acc: 0.8409 - val_auc: 0.9179\n",
      "Epoch 6/20\n",
      "36745/36745 [==============================] - 110s 3ms/step - loss: 0.1909 - acc: 0.9503 - auc: 0.9224 - val_loss: 0.6284 - val_acc: 0.8214 - val_auc: 0.9291\n",
      "Epoch 7/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.1534 - acc: 0.9606 - auc: 0.9318 - val_loss: 0.6392 - val_acc: 0.8592 - val_auc: 0.9371\n",
      "Epoch 8/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.1160 - acc: 0.9706 - auc: 0.9374 - val_loss: 0.6859 - val_acc: 0.8278 - val_auc: 0.9416\n",
      "Epoch 9/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.0989 - acc: 0.9755 - auc: 0.9424 - val_loss: 0.8224 - val_acc: 0.8406 - val_auc: 0.9458\n",
      "Epoch 10/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.0890 - acc: 0.9783 - auc: 0.9458 - val_loss: 0.7787 - val_acc: 0.8438 - val_auc: 0.9486\n",
      "Epoch 11/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.0674 - acc: 0.9847 - auc: 0.9487 - val_loss: 0.9981 - val_acc: 0.8004 - val_auc: 0.9508\n",
      "Epoch 12/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.0645 - acc: 0.9843 - auc: 0.9511 - val_loss: 0.9147 - val_acc: 0.8494 - val_auc: 0.9532\n",
      "Epoch 13/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.0635 - acc: 0.9860 - auc: 0.9525 - val_loss: 0.9189 - val_acc: 0.8624 - val_auc: 0.9543\n",
      "Epoch 14/20\n",
      "36745/36745 [==============================] - 135s 4ms/step - loss: 0.0450 - acc: 0.9891 - auc: 0.9533 - val_loss: 1.0490 - val_acc: 0.8577 - val_auc: 0.9550\n",
      "Epoch 15/20\n",
      "36745/36745 [==============================] - 109s 3ms/step - loss: 0.0442 - acc: 0.9898 - auc: 0.9540 - val_loss: 0.9734 - val_acc: 0.8599 - val_auc: 0.9555\n",
      "Epoch 16/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.0494 - acc: 0.9885 - auc: 0.9546 - val_loss: 1.0148 - val_acc: 0.8545 - val_auc: 0.9558\n",
      "Epoch 17/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.0424 - acc: 0.9914 - auc: 0.9551 - val_loss: 1.0435 - val_acc: 0.8498 - val_auc: 0.9563\n",
      "Epoch 18/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.0365 - acc: 0.9927 - auc: 0.9557 - val_loss: 1.2780 - val_acc: 0.8201 - val_auc: 0.9567\n",
      "Epoch 19/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.0306 - acc: 0.9933 - auc: 0.9564 - val_loss: 1.2051 - val_acc: 0.8398 - val_auc: 0.9573\n",
      "Epoch 20/20\n",
      "36745/36745 [==============================] - 108s 3ms/step - loss: 0.0368 - acc: 0.9919 - auc: 0.9568 - val_loss: 1.1770 - val_acc: 0.8484 - val_auc: 0.9576\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in skf.split(train, train.labels):\n",
    "    \n",
    "    train_, valid_ = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "    fold = 'Fold ' + str(i + 1)\n",
    "    print('========')\n",
    "    print(fold)\n",
    "    print('========')\n",
    "\n",
    "    cross_val_dict = {}\n",
    "\n",
    "    # Define model\n",
    "    hrnn = Hybrid_RNN(max_words=max_words, max_len=max_len)\n",
    "    hrnn.init_hyperparams(best_hyperparameters)\n",
    "    hrnn.init_network(feature_cols)\n",
    "\n",
    "    # Pad sequence\n",
    "    sequences_train_matrix = sequence.pad_sequences(train_['sequence'], maxlen=max_len, value=2)\n",
    "    sequences_valid_matrix = sequence.pad_sequences(valid_['sequence'], maxlen=max_len, value=2)\n",
    "    sequences_test_matrix = sequence.pad_sequences(test['sequence'], maxlen=max_len, value=2)\n",
    "    \n",
    "    # Train model on train, valid\n",
    "    hrnn.train(sequences_train_matrix, train_[feature_cols], train_.labels,\n",
    "               sequences_valid_matrix, valid_[feature_cols], valid_.labels,\n",
    "               class_weight=class_weight,\n",
    "               epochs=20,\n",
    "               patience=2)\n",
    "    \n",
    "    # Score model on valid and test\n",
    "    y_pred_valid = hrnn.model.predict([sequences_valid_matrix, valid_[feature_cols]])\n",
    "    y_pred_test = hrnn.model.predict([sequences_test_matrix, test[feature_cols]])\n",
    "\n",
    "    # Save model and scores\n",
    "    cross_val_dict['y_pred_test'] = y_pred_test\n",
    "\n",
    "    y_true_valid = valid_.labels\n",
    "\n",
    "    cross_val_dict['acc_05_valid'] = accuracy_score(y_true_valid, (y_pred_valid > 0.5))\n",
    "\n",
    "    cross_val_dict['best_acc_valid'], cross_val_dict['best_thresh_valid'] = max_accuracy(y_true_valid, y_pred_valid)\n",
    "\n",
    "    result_dict[fold] = cross_val_dict\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack models over folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:45:35.544860Z",
     "start_time": "2019-02-12T22:45:35.540698Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack models\n",
    "result_dict['stacked_y_pred'] = np.mean(np.array([result_dict[fold]['y_pred_test'] for fold in ['Fold ' + str(i + 1) for i in range(5)]]), axis=0)\n",
    "result_dict['stacked_thresh_valid'] = np.mean([result_dict[fold]['best_thresh_valid'] for fold in ['Fold ' + str(i + 1) for i in range(5)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:45:35.553808Z",
     "start_time": "2019-02-12T22:45:35.547131Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score on real test\n",
    "predictions = result_dict['stacked_y_pred'] >= result_dict['stacked_thresh_valid']\n",
    "\n",
    "# Map binary labels for real prediction format\n",
    "map_label = {0: 'C', 1: 'M'}\n",
    "mapped_predictions = [map_label[int(pred)] for pred in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:45:35.574068Z",
     "start_time": "2019-02-12T22:45:35.556909Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dump results\n",
    "with open('Data/Test/predicted_labels.pkl', 'wb') as f:\n",
    "        pkl.dump(mapped_predictions, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_python3",
   "language": "python",
   "name": "venv_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "333px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
